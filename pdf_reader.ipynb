{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "from thefuzz import fuzz\n",
    "from thefuzz import process\n",
    "from pprint import pprint\n",
    "from dataclasses import dataclass, field\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CompPlanScraper:\n",
    "    page: pdfplumber.page.Page\n",
    "    height: float\n",
    "    width: float\n",
    "\n",
    "    #################################\n",
    "    # bbox_rules = (x0, y0, x1, y1) #\n",
    "    #################################\n",
    "\n",
    "    def parse_col_coordinates(self):\n",
    "        cord_roles, cols = [], []\n",
    "        contents = self.page.extract_text_lines()\n",
    "\n",
    "        for content in contents:\n",
    "            if (top := content[\"top\"]) >= 100 and (bottom := content[\"bottom\"]) <= self.height - 50:\n",
    "                title_text = \"\"\n",
    "                for char in content[\"chars\"]:\n",
    "                    if \"bold\" in char.get(\"fontname\").lower():\n",
    "                        char_text = char.get(\"text\")\n",
    "                        title_text += char_text\n",
    "                cord_roles.append(title_text.strip())\n",
    "                x0 = content[\"x0\"]\n",
    "                cols.append(x0)\n",
    "                \n",
    "        cols.append(self.width)\n",
    "        cols = sorted(list(set(cols)))\n",
    "        cord_roles = [role for role in cord_roles if role != \"\"]\n",
    "        return cord_roles, cols\n",
    "\n",
    "    def parse_text_within_bbox(self, bbox_rules):\n",
    "        text = self.page.within_bbox(bbox_rules).extract_text()\n",
    "        return text\n",
    "\n",
    "    def parse_doc_title(self):\n",
    "        title_bbox = (0, 20, self.page.width, 120) \n",
    "        title = self.parse_text_within_bbox(title_bbox)\n",
    "        return title\n",
    "\n",
    "    def parse_comp_plan_roles(self):\n",
    "        cord_roles, cols = self.parse_col_coordinates()\n",
    "\n",
    "        roles = []\n",
    "        for i in range(len(cols))[:-1]:\n",
    "            x0, x1, y0, y1 = cols[i], cols[i+1], 120, self.height - 50\n",
    "            role = self.parse_text_within_bbox((x0, y0, x1, y1))\n",
    "            roles.extend(role.split(\"\\n\"))\n",
    "        \n",
    "        roles = list(map(lambda x: x.strip(), roles))\n",
    "\n",
    "        roles_with_titles = {}\n",
    "        current_title = \"\"\n",
    "        for role in roles:\n",
    "            matches = process.extract(role, cord_roles, scorer=fuzz.ratio)\n",
    "            if matches[0][1] > 90:\n",
    "                if current_title == role:\n",
    "                    roles_with_titles[current_title].append(role)\n",
    "                else:\n",
    "                    current_title = role\n",
    "                    roles_with_titles.setdefault(current_title, [])\n",
    "            else:\n",
    "                roles_with_titles[current_title].append(role)\n",
    "        return roles_with_titles\n",
    "\n",
    "@dataclass\n",
    "class CompPlanDetails(CompPlanScraper): \n",
    "            \n",
    "    def parse_details_title(self, merged_page=False):\n",
    "        if not merged_page:\n",
    "            metric_bucket_info = 70\n",
    "        else:\n",
    "            metric_bucket_info = self.page.search(\"Metric Bucket\")[0][\"top\"]\n",
    "        title_bbox = (0, metric_bucket_info - 50, self.page.width / 2, metric_bucket_info + 10)  \n",
    "        title = self.parse_text_within_bbox(title_bbox)\n",
    "        try:\n",
    "            title_type = [item[\"chars\"][0].get(\"fontname\") for item in self.page.within_bbox(title_bbox).extract_text_lines()][0]\n",
    "        except:\n",
    "            title_type = \"None\"\n",
    "        return (title, title_type)\n",
    "\n",
    "    def parse_attainment_modifiers(self):\n",
    "        attainment_modifiers_table_details = [(content[\"top\"], content[\"x0\"]) for content in self.page.search(\"Attainment Modifiers\")][-1] # (top, x0)\n",
    "        attainment_modifiers = self.page.within_bbox((attainment_modifiers_table_details[1]-30, attainment_modifiers_table_details[0], self.width - 100, self.height)).extract_tables()\n",
    "        attainment_modifiers_all = []\n",
    "        for attainment_modifier in attainment_modifiers:\n",
    "            attainment_modifiers_all.extend(attainment_modifier)\n",
    "        return attainment_modifiers_all\n",
    "    \n",
    "    def parse_remaining_attainment_modifiers(self):\n",
    "        attainment_modifiers = self.page.within_bbox((0, 20, self.width, self.height)).extract_table()  \n",
    "        return attainment_modifiers\n",
    "\n",
    "    def parse_metric_bucket(self):\n",
    "        metric_title = [(content[\"top\"], content[\"x0\"]) for content in self.page.search(\"Metric Bucket\")][0]\n",
    "        try:\n",
    "            attainment_modifiers_title = [(content[\"top\"], content[\"x0\"]) for content in self.page.search(\"Attainment Modifiers\")][0]\n",
    "        except IndexError:\n",
    "            attainment_modifiers_title = [self.height]\n",
    "        paycurve_title = [(content[\"top\"], content[\"x0\"]) for content in self.page.search(\"PayCurve\")][0]\n",
    "        contents = self.page.within_bbox((metric_title[1], metric_title[0], paycurve_title[1], attainment_modifiers_title[0])).extract_tables()\n",
    "        return contents\n",
    "\n",
    "    def parse_paycurve(self):\n",
    "        paycurve_table_details = [(content[\"top\"], content[\"x0\"]) for content in self.page.search(\"PayCurve\")][-1] # (top, x0)\n",
    "        paycurve = self.page.within_bbox((paycurve_table_details[1]-80, paycurve_table_details[0], paycurve_table_details[1] + 150, paycurve_table_details[0]+120)).extract_table()\n",
    "        return paycurve\n",
    "\n",
    "    def parse_gate_text(self):\n",
    "        gate_text_table_details = [(content[\"top\"], content[\"x0\"]) for content in self.page.search(\"Gate Text\")][-1] # (top, x0)\n",
    "        gate_text = self.page.within_bbox((gate_text_table_details[1]-80, gate_text_table_details[0], gate_text_table_details[1] + 150, gate_text_table_details[0]+100)).extract_text()\n",
    "        return \" \".join([content for content in gate_text.split(\"\\n\") if content != \"\" ])\n",
    "\n",
    "    def parse_quota_cadence(self):\n",
    "        quota_cadence_table_details = [(content[\"top\"], content[\"x0\"]) for content in self.page.search(\"Quota Cadence\")][-1] # (top, x0)\n",
    "        quota_cadence = self.page.within_bbox((quota_cadence_table_details[1]-80, quota_cadence_table_details[0], quota_cadence_table_details[1] + 150, quota_cadence_table_details[0]+100)).extract_text()\n",
    "        return \" \".join([content for content in quota_cadence.split(\"\\n\") if content != \"\" ]).replace(\"Quota Cadence \", \"\")\n",
    "\n",
    "    def parse_unbalanced(self):\n",
    "        unbalanced_table_details = [(content[\"top\"], content[\"x0\"]) for content in self.page.search(\"Unbalanced\")][0] # (top, x0)\n",
    "        unbalanced = self.page.within_bbox((unbalanced_table_details[1]-80, unbalanced_table_details[0], self.width, unbalanced_table_details[0]+200)).extract_text()\n",
    "        return \" \".join([content for content in unbalanced.split(\"\\n\") if content != \"\" ]).replace(\"Unbalanced \", \"\").replace(\"Other Information\", \"\")\n",
    "\n",
    "    def parse_other_information(self):\n",
    "        metric_bucket_info = self.page.search(\"Metric Bucket\")[0][\"top\"]\n",
    "        other_information_table_details = [(content[\"top\"], content[\"x0\"]) for content in self.page.within_bbox((0, metric_bucket_info, self.width, self.height)).search(\"Other Information\")][0] # (top, x0)\n",
    "        try:\n",
    "            other_information = self.page.within_bbox((other_information_table_details[1]-50, other_information_table_details[0], self.width, other_information_table_details[0]+300)).extract_text() \n",
    "        except ValueError:\n",
    "            other_information = self.page.within_bbox((other_information_table_details[1]-50, other_information_table_details[0], self.width, self.height)).extract_text()\n",
    "        return \" \".join([content for content in other_information.split(\"\\n\") if content != \"\" ]).replace(\"Other Information \", \"\")\n",
    "\n",
    "    def get_remaining_text_x0s(self, remaining_rows):\n",
    "        remaining_text_x0s = []\n",
    "        for remaining_row in remaining_rows:\n",
    "            if \"dell.com:\" not in (remaining_text := remaining_row[\"text\"]):\n",
    "                remaining_text_x0 = remaining_row[\"x0\"]\n",
    "                remaining_text_x0s.append((remaining_text_x0, remaining_text))\n",
    "        remaining_text_x0s = sorted(remaining_text_x0s, key=lambda x: x[0])\n",
    "        return remaining_text_x0s\n",
    "\n",
    "    def parse_product_eligibility(self, last_page=False):\n",
    "        product_eligibility_table_details = [(content[\"top\"], content[\"x0\"]) for content in self.page.search(\"Product Eligibility\")][-1] # (top, x0)\n",
    "        table_start_xs = [l1[\"x0\"] for l1 in self.page.search(\"L1 Type\")]  \n",
    "        potential_boundaries = [\"Other Information\", \"error has occurred\"]\n",
    "        boundary = None\n",
    "        for potential_boundary in potential_boundaries:\n",
    "            try:\n",
    "                boundary = self.page.search(potential_boundary)[0][\"x0\"]\n",
    "                break\n",
    "            except IndexError:\n",
    "                pass\n",
    "        if not boundary:\n",
    "            boundary = self.width\n",
    "        table_start_xs.append(boundary)\n",
    "        all_cols_infos = []\n",
    "        pe_dfs = []\n",
    "        for idx in range(len(table_start_xs)-1):\n",
    "            x0, x1 = table_start_xs[idx], table_start_xs[idx+1]\n",
    "            top_boundary = self.page.search(\"Click on Metric names\")[0][\"top\"]\n",
    "            left_shift = 100\n",
    "            top_shift = 100\n",
    "            product_eligibility = self.page.within_bbox((0 if idx == 0 else x0 - left_shift, top_boundary, x1, self.page.bbox[3])).extract_table()\n",
    "            pe_df = pd.DataFrame(product_eligibility)\n",
    "            pe_df.columns = pe_df.iloc[0, :].ffill()\n",
    "            # print(pe_df)\n",
    "            try:\n",
    "                pe_df = pe_df.iloc[1:, :]\n",
    "                pe_df = pe_df.replace(\"\", np.nan).ffill().reset_index(drop=True)\n",
    "                row_infos = pe_df.iloc[1, :].to_list()\n",
    "                col_infos = []\n",
    "                for row in row_infos:\n",
    "                    try:\n",
    "                        col_info = self.page.within_bbox((0 if idx == 0 else x0 - left_shift, product_eligibility_table_details[0] - 10, x1, self.page.bbox[3] - 30)).search(row.split(\"\\n\")[0])\n",
    "                        col_infos.append(col_info[0][\"x0\"])\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "                all_cols_infos.append(col_infos)\n",
    "                if not len(col_infos) == 0:\n",
    "                    last_row_infos = product_eligibility[-1]\n",
    "                    # print(last_row_infos)\n",
    "                    for last_row_info in last_row_infos:\n",
    "                        try:\n",
    "                            last_row_top = [info[\"top\"] for info in self.page.within_bbox((0 if idx == 0 else x0 - left_shift, product_eligibility_table_details[0], x1, self.page.bbox[3] - 30)).search(last_row_info)]\n",
    "                            break\n",
    "                        except Exception as e:\n",
    "                            # print(e)\n",
    "                            continue\n",
    "                    last_row_text = \" \".join([content for content in product_eligibility[-1] if content != \"\" and content != None])\n",
    "                    remaining_row = self.page.within_bbox((0 if idx == 0 else x0 - left_shift, last_row_top[0] + 10, x1, self.page.bbox[3])).extract_text()\n",
    "                    if \"Metric Bucket\" not in remaining_row:\n",
    "                        remaining_row_text = \" \".join([content for content in remaining_row.split(\"\\n\") if content != \"\" ])\n",
    "                        if (similarity := text_comparison(remaining_row_text, last_row_text)) < 10:\n",
    "                            remaining_rows = self.page.within_bbox((0 if idx == 0 else x0 - left_shift, last_row_top[0] + 10, x1, self.page.bbox[3])).extract_text_lines()\n",
    "                            remaining_text_x0s = self.get_remaining_text_x0s(remaining_rows)\n",
    "                            remaining_table = categorize_col_infos(remaining_text_x0s, col_infos)\n",
    "                            cols = pe_df.columns.tolist()\n",
    "                            if len(remaining_table) == len(cols):\n",
    "                                pe_df.columns = range(len(cols))\n",
    "                                if sum([bool(item) for item in remaining_table]) > 0:\n",
    "                                    remaining_rows_info = pd.DataFrame(remaining_table, index=pe_df.columns).replace(\"\", np.nan).T\n",
    "                                    pe_df = pd.concat([pe_df, remaining_rows_info], axis=0).reset_index(drop=True)\n",
    "                                pe_df.columns = cols\n",
    "            except IndexError:\n",
    "                pass\n",
    "            # print(pe_df)\n",
    "            # print(\"==========\")\n",
    "            pe_dfs.append(pe_df)\n",
    "        return pe_dfs if not last_page else all_cols_infos\n",
    "\n",
    "    def parse_next_page_product_eligibility(self):\n",
    "        text_cols = self.get_remaining_text_x0s(self.page.within_bbox((0, 30, self.page.width, self.page.bbox[3])).extract_text_lines())\n",
    "        return text_cols\n",
    "    \n",
    "    def check_if_title_is_empty(self, title) -> bool:\n",
    "        return len(self.page.search(title)) == 0\n",
    "    \n",
    "def return_none_if_empty(func):\n",
    "    try:\n",
    "        return func()\n",
    "    except IndexError:\n",
    "        return None\n",
    "\n",
    "def output_to_txt(roles, infos):\n",
    "    with open(\"pdf_reader.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"Roles: {roles}\\n\")\n",
    "        for info in infos:\n",
    "            f.write(rf\"Information: {info}\\n\")\n",
    "\n",
    "def text_comparison(text1, text2):\n",
    "    return fuzz.ratio(text1, text2)\n",
    "\n",
    "def categorize_col_infos(col_infos: list[tuple], benchmark_infos: list):\n",
    "    targeted_cols = [''] * len(benchmark_infos)\n",
    "    benchmark_infos = sorted(list(set(benchmark_infos)))\n",
    "    for col_info in col_infos:\n",
    "        num_col  = 0\n",
    "        # print(benchmark_infos)\n",
    "        for benchmark_info in benchmark_infos:\n",
    "            if col_info[0] >= benchmark_info:\n",
    "                num_col += 1\n",
    "        if num_col > 0:\n",
    "            # print(\"num of col:\",num_col - 1)\n",
    "            targeted_cols[num_col - 1] += col_info[1] + \"\\n\"\n",
    "    return [col.strip() for col in targeted_cols]\n",
    "\n",
    "def parse_content_details(title, comp_plan_details):\n",
    "    attainment_modifiers = return_none_if_empty(comp_plan_details.parse_attainment_modifiers)\n",
    "    metric_bucket = return_none_if_empty(comp_plan_details.parse_metric_bucket)\n",
    "    paycurve = return_none_if_empty(comp_plan_details.parse_paycurve)\n",
    "    gate_text = return_none_if_empty(comp_plan_details.parse_gate_text)\n",
    "    quota_cadence = return_none_if_empty(comp_plan_details.parse_quota_cadence)\n",
    "    unbalanced = return_none_if_empty(comp_plan_details.parse_unbalanced)\n",
    "    other_information = return_none_if_empty(comp_plan_details.parse_other_information)\n",
    "    info = {\n",
    "        \"Title\": title,\n",
    "        \"Metric Bucket Weightage\": metric_bucket,\n",
    "        \"Pay Curve\": paycurve,\n",
    "        \"Gate Text\": gate_text,\n",
    "        \"Quota Cadence\": quota_cadence,\n",
    "        \"Unbalanced\": unbalanced,\n",
    "        \"Attainment Modifiers\": attainment_modifiers,\n",
    "        \"Other Information\": other_information\n",
    "    }\n",
    "    return info\n",
    "\n",
    "def main(file):\n",
    "    infos = []\n",
    "    roles = None\n",
    "    with pdfplumber.open(file) as pdf:\n",
    "        pages = pdf.pages\n",
    "        for index, page in list(enumerate(pages))[:]:\n",
    "            # print(index + 1)\n",
    "            # print(\"Extracting Info from page {}\".format(index))\n",
    "            page_scraper = CompPlanScraper(page, page.height, page.width)\n",
    "            if index == 0:\n",
    "                roles = page_scraper.parse_comp_plan_roles()\n",
    "                infos.append({\n",
    "                        \"Document Title\":  page_scraper.parse_doc_title(),\n",
    "                        \"Roles Availability\": roles\n",
    "                    })\n",
    "            else:\n",
    "                comp_plan_details = CompPlanDetails(page, page.height, page.width)\n",
    "                title, title_type = comp_plan_details.parse_details_title()\n",
    "                # print(title)\n",
    "                if title != \"Product Eligibility\" and \"bold\" in title_type.lower():\n",
    "                    if comp_plan_details.check_if_title_is_empty(\"Metric Bucket\"):\n",
    "                        last_info = infos[-1]\n",
    "                        last_info[\"Attainment Modifiers\"] = return_none_if_empty(comp_plan_details.parse_remaining_attainment_modifiers)\n",
    "                        infos[-1] = last_info\n",
    "                    else:\n",
    "                        info = parse_content_details(title, comp_plan_details)\n",
    "                        infos.append(info)\n",
    "\n",
    "                elif title == \"Product Eligibility\" and \"bold\" in title_type.lower():\n",
    "                    if comp_plan_details.check_if_title_is_empty(\"Metric Bucket\"):\n",
    "\n",
    "                        product_eligibility = return_none_if_empty(comp_plan_details.parse_product_eligibility)\n",
    "\n",
    "                        infos.append({\n",
    "                            \"product_eligibility\": product_eligibility\n",
    "                        })\n",
    "                    else:\n",
    "                        product_eligibility = return_none_if_empty(comp_plan_details.parse_product_eligibility)\n",
    "\n",
    "                        merged_page_new_title = comp_plan_details.parse_details_title(merged_page=True)[0]\n",
    "                        info = parse_content_details(merged_page_new_title, comp_plan_details)\n",
    "                        \n",
    "                        infos.append({\n",
    "                            \"product_eligibility\": product_eligibility\n",
    "                        })\n",
    "                        infos.append(info)\n",
    "                        \n",
    "                else: ## if the page do not have any title or simply do not have anything\n",
    "                    if title_type == \"None\":\n",
    "                        continue\n",
    "                    num_page_to_last_table = 1\n",
    "                    while True:\n",
    "                        try:\n",
    "                            last_page = pages[index - num_page_to_last_table]\n",
    "                            last_page_tables = CompPlanDetails(last_page, last_page.height, last_page.width).parse_product_eligibility(last_page=True)\n",
    "                            break\n",
    "                        except IndexError:\n",
    "                            num_page_to_last_table += 1\n",
    "                    remaining_table = comp_plan_details.parse_next_page_product_eligibility()\n",
    "                    tables = {}\n",
    "                    for last_page_table_idx, last_page_table in enumerate(last_page_tables):\n",
    "                        table = categorize_col_infos(remaining_table, last_page_table)\n",
    "                        if sum([bool(item) for item in table]) > 0:\n",
    "                            tables[last_page_table_idx] = table\n",
    "                    pe_dfs = infos[-1][\"product_eligibility\"]\n",
    "                    # print(len(pe_dfs))\n",
    "                    for table_idx in tables:\n",
    "                        pe_df = pe_dfs[table_idx]\n",
    "                        df_cols = pe_df.columns.tolist()\n",
    "                        pe_df.columns = range(len(df_cols))\n",
    "                        # print(pe_df)\n",
    "                        remaining_df = pd.DataFrame(tables[table_idx], index=pe_df.columns).replace(\"\", np.nan).T\n",
    "                        pe_df = pd.concat([pe_df, remaining_df], axis=0).reset_index(drop=True)\n",
    "                        pe_df.columns = df_cols\n",
    "                        pe_dfs[table_idx] = pe_df\n",
    "                    infos[-1][\"product_eligibility\"] = pe_dfs\n",
    "    return infos\n",
    "\n",
    "    # output_to_txt(roles, infos)\n",
    "\n",
    "    # https://coinsappadm.amer.dell.com:4443/ords/f?p=105:3:10855050605894::::P3_PLAN_ID,P3_METRIC,P3_PERIOD:3249,AI+Optimized+Svr+Rev,FY25-H2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataclass' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mComplanTemplate\u001b[39;00m:\n\u001b[0;32m      3\u001b[0m     info: \u001b[38;5;28mdict\u001b[39m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender_table_of_contents\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataclass' is not defined"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class ComplanTemplate:\n",
    "    info: dict\n",
    "\n",
    "    def render_table_of_contents(self):\n",
    "        info = self.info\n",
    "        render_template = f\"\"\"\\\n",
    "# Document Title: {info[\"Document Title\"]}\n",
    "## Roles Availabiity\n",
    "        \"\"\"\n",
    "        for role, details in info[\"Roles Availability\"].items():\n",
    "            render_template += f\"\"\"\n",
    "    - {role}\n",
    "        - {[detail.strip() for detail in details if detail.strip() != \"\"]}\n",
    "\"\"\"\n",
    "        return render_template \n",
    "    \n",
    "    def render_role_details(self):\n",
    "        return f\"\"\"\n",
    "{self.render_role_title(self.info)}\n",
    "### the Metric Bucket Weightage of {self.info[\"Title\"]} is {self.render_metric_bucket_weightage(self.info)}\n",
    "### the Pay Curve of {self.info[\"Title\"]} is\\n{self.render_paycurve(self.info)}\n",
    "{self.render_other_infos(self.info)}\n",
    "### the Attainment Modifier of {self.info[\"Title\"]} is: {self.render_attainment_modifier(self.info)}\n",
    "\"\"\"\n",
    "    \n",
    "    def render_role_title(self, info):\n",
    "        return f\"## Role Title: {info['Title']}\"\n",
    "     \n",
    "    def render_metric_bucket_weightage(self, info):\n",
    "        try:\n",
    "            buckets = info[\"Metric Bucket Weightage\"][0][0][0].split(\"\\n\")\n",
    "        except IndexError:\n",
    "            buckets = [\"No Data\"]\n",
    "        render_template = f\"\"\"\\\n",
    "\"\"\"\n",
    "        metrics = []\n",
    "        for idx, bucket in enumerate(buckets):\n",
    "            # print(bucket)\n",
    "            if \"%\" in bucket:\n",
    "                metric_info = bucket.replace(\"■\", \"\").strip()\n",
    "                match_pattern = r\"\\s+(?=\\d+\\.?\\d*%)\\b\"\n",
    "                metric_info = re.split(match_pattern, metric_info)\n",
    "                if len(metric_info) < 2:\n",
    "                    metric_info = re.split(match_pattern, buckets[idx - 1] + \" \" + bucket.replace(\"■\", \"\").strip()) \n",
    "                metrics.append(metric_info)\n",
    "        # print(metrics)\n",
    "        render_template += f\"\"\"\n",
    "{pd.DataFrame(metrics, columns=[\"Metric Bucket\", \"Weightage\"]).to_markdown(index=False)}\n",
    "\n",
    "\"\"\"\n",
    "        return render_template\n",
    "    \n",
    "    def render_paycurve(self, info):\n",
    "        paycurve = pd.DataFrame(info[\"Pay Curve\"], columns=[\"Attainment\", \"Pay Out\"]).to_markdown(index=False)\n",
    "        return f\"\"\"\\\n",
    "{paycurve}\n",
    "\"\"\"\n",
    "    \n",
    "    def render_other_infos(self, info):\n",
    "        gate_text = info.get(\"Gate Text\", \"\")\n",
    "        quota_cadence = info.get(\"Quota Cadence\", \"\")\n",
    "        unbalanced = info.get(\"Unbalanced\", \"\")\n",
    "        other_information = info.get(\"Other Information\", \"\")\n",
    "        return f\"\"\"\\\n",
    "### Gate Text:\n",
    "the gate text of {info['Title']} is {gate_text}\n",
    "### Quota Cadence:\n",
    "the Quota Cadence of {info['Title']} is {quota_cadence}\n",
    "### Unbalanced:\n",
    "the Unbalanced of {info['Title']} is {unbalanced}\n",
    "### Other Information:\n",
    "the Other Information of {info['Title']} is {other_information}\n",
    "\"\"\"\n",
    "    \n",
    "    def render_attainment_modifier(self, info):\n",
    "        modifier_df = pd.DataFrame(info[\"Attainment Modifiers\"]).dropna(thresh=2)\n",
    "        spliited_modifiers = []\n",
    "        for row, value in modifier_df.iterrows():\n",
    "            products = value[0]\n",
    "            modifiers = np.where(value[[1]].notna(), value[1], value[2])[0] if len(value) > 2 else value[1]\n",
    "            for modifier in modifiers.split(\"\\n\"):\n",
    "                for product in products.split(\"\\n\"):\n",
    "                    spliited_modifiers.append([product, modifier])\n",
    "        attainment_modifier_df = pd.DataFrame(spliited_modifiers, columns=[\"Product\", \"Modifier\"]).drop_duplicates([\"Product\", \"Modifier\"])\n",
    "        return f\"\"\"\\\n",
    "{list(attainment_modifier_df.values) if type(attainment_modifier_df) is not str else attainment_modifier_df }\n",
    "\"\"\"\n",
    "    \n",
    "    def render_product_eligibilities(self, role_titles: list[str]):\n",
    "        info = self.info[\"product_eligibility\"]\n",
    "        render_template = f\"\"\"\\n\n",
    "### the Product Eligibility of {role_titles} is:\n",
    "\"\"\"\n",
    "        for df in info:\n",
    "            # print(df)\n",
    "            render_template += f\"\"\"\n",
    "{list(df.values)}\n",
    "\"\"\"\n",
    "        return render_template\n",
    "\n",
    "def render_comp_plan_template(comp_plan):\n",
    "    template = \"\"\n",
    "    role_titles = []\n",
    "    for info in comp_plan:\n",
    "        # print(info)\n",
    "        content = ComplanTemplate(info)\n",
    "        if \"Document Title\" in info:\n",
    "            template += content.render_table_of_contents()\n",
    "        elif \"Title\" in info:\n",
    "            template += content.render_role_details()\n",
    "            role_titles.append(info[\"Title\"])\n",
    "        else:\n",
    "            template += content.render_product_eligibilities(role_titles)\n",
    "            role_titles = []\n",
    "            # print(template)\n",
    "        template += \"===\" * 60 + \"\\n\"\n",
    "    return template\n",
    "\n",
    "def output_template_to_txt(template):\n",
    "    with open(\"Core Comp Plan.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n"
     ]
    }
   ],
   "source": [
    "files = [\n",
    "    r\"C:\\Users\\Tekyaw_Ng\\Downloads\\2HFY25 - Core Compensation Plans 2 (4).pdf\",\n",
    "    # r\"C:\\Users\\Tekyaw_Ng\\Downloads\\2HFY25 - Consumer & SMB Compensation Plans 1 (3).pdf\",\n",
    "    # r\"C:\\Users\\Tekyaw_Ng\\Downloads\\2HFY25 Channel and Distribution Compensation Plans 1 (2).pdf\",\n",
    "    # r\"C:\\Users\\Tekyaw_Ng\\Downloads\\2HFY25 - Presales and ISG Specialists Compensation Plan 1 (2).pdf\"\n",
    "]\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "comp_plans = []\n",
    "\n",
    "for file in files:\n",
    "    # print(file)\n",
    "    comp_plan = main(file)\n",
    "    comp_plans.append(comp_plan)\n",
    "# comp_plans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = render_comp_plan_template(comp_plans[0])\n",
    "output_template_to_txt(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
